Course Code : ECPE81
Course Title : Pattern recognition and machined learning
ec 3 0 0 3
Prerequisites
(Course code)

: ECPC32

Course Type : PE

Course Learning Objectives:
The student should be able to understand and apply the various concepts of Pattern recognition
and machine learning.
Course Content:
UNIT I
Introduction
Polynomial Curve Fitting, Probability Theory Model Selection, The Curse of Dimensionality,
Decision Theory, Information Theory,Probability Distributions,Binary Variables, Multinomial
Variables, The Gaussian Distribution ,The Exponential Family, Nonparametric Methods,Linear
Models for Regression, Linear Basis Function Models, The Bias-Variance Decomposition,
Bayesian Linear Regression, Bayesian Model Comparison, The Evidence Approximation,
Limitations of Fixed Basis Functions, Linear Models for Classification, Discriminant Functions,
Probabilistic Generative Models, Probabilistic Discriminative Models The Laplace
Approximation, Bayesian Logistic Regression.
UNIT II
Feed-forward Network Functions
Network Training, Error Backpropagation, The Hessian Matrix, Regularization in Neural
Networks, Mixture Density Networks, Bayesian Neural Networks Dual Representations,
Constructing Kernels, Radial Basis Function Networks, Gaussian Processes,Sparse Kernel
Machines, Maximum Margin Classifiers, Relevance Vector Machines.
UNIT III
Graphical Models
Bayesian Networks, Conditional Independence, Markov Random Fields, Inference in Graphical
Models, Mixture Models and EM, K-means Clustering, Mixtures of Gaussians, An Alternative
View of EM, The EM Algorithm in General, Approximate Inference, Variational Inference,

Variational Mixture of Gaussians, Variational Linear Regression, Exponential Family
Distributions, Local Variational Methods, Variational Logistic Regression, Expectation
Propagation,Sampling Methods, Basic Sampling Algorithms, Markov Chain Monte Carlo, Gibbs
Sampling, Slice Sampling, The Hybrid Monte Carlo Algorithm, Estimating the Partition Function.
UNIT IV
Continuous Latent Variables
Principal Component Analysis, Probabilistic PCA, Kernel PCA, Nonlinear Latent Variable
Models, Sequential Data , Markov Models, Hidden Markov Models, Linear Dynamical Systems,
Combining Models, Bayesian Model Averaging, Committees, Boosting, Tree-based Models,
Conditional Mixture Models.
Reference Books:
1. C. M. Bishop, Pattern Recognition and machine learning, springer, 2006.
2. Tom M. Mitchell, Machine Learning, Mc Graw-Hill, 1997.
Course outcomes:
At the end of the course student will be able to:
1. Develop the understanding about fundamentals of pattern recognition and machine
learning.
2. Apply supervised and unsupervised learning techniques.
3. Understand and apply SVM.
4. Understand different graphical models.
5. Understand different clustering techniques.
6. Apply continuous latent variable and its mixture models.